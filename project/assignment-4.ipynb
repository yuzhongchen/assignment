{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJvw-FG9eVk3",
        "outputId": "fe1b5c8a-a32a-407f-931d-5756bc0cf7fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting webvtt-py\n",
            "  Downloading webvtt_py-0.5.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.8.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata (27 kB)\n",
            "Collecting sentence-transformers\n",
            "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting qdrant-client\n",
            "  Using cached qdrant_client-1.14.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting bertopic\n",
            "  Downloading bertopic-0.17.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting gradio\n",
            "  Using cached gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting ffmpeg-python\n",
            "  Using cached ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
            "  Downloading murmurhash-1.0.12-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
            "  Downloading cymem-2.0.11-cp39-cp39-macosx_10_9_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
            "  Downloading preshed-3.0.9-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
            "  Downloading thinc-8.3.6-cp39-cp39-macosx_10_9_x86_64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
            "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
            "  Downloading srsly-2.5.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (19 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
            "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
            "  Downloading typer-0.15.3-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/miniconda3/lib/python3.9/site-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /opt/miniconda3/lib/python3.9/site-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.9/site-packages (from spacy) (2.31.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
            "  Using cached pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
            "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.9/site-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.9/site-packages (from spacy) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/chenyuzhong/.local/lib/python3.9/site-packages (from spacy) (24.2)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
            "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: torch>=1.11.0 in /opt/miniconda3/lib/python3.9/site-packages (from sentence-transformers) (2.2.2)\n",
            "Collecting scikit-learn (from sentence-transformers)\n",
            "  Using cached scikit_learn-1.6.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
            "Requirement already satisfied: scipy in /opt/miniconda3/lib/python3.9/site-packages (from sentence-transformers) (1.13.1)\n",
            "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
            "  Using cached huggingface_hub-0.31.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: Pillow in /opt/miniconda3/lib/python3.9/site-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/chenyuzhong/.local/lib/python3.9/site-packages (from sentence-transformers) (4.12.2)\n",
            "Collecting grpcio>=1.41.0 (from qdrant-client)\n",
            "  Using cached grpcio-1.71.0-cp39-cp39-macosx_10_14_universal2.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /opt/miniconda3/lib/python3.9/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.2)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
            "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting protobuf>=3.20.0 (from qdrant-client)\n",
            "  Using cached protobuf-6.30.2-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /opt/miniconda3/lib/python3.9/site-packages (from qdrant-client) (2.1.0)\n",
            "Collecting hdbscan>=0.8.29 (from bertopic)\n",
            "  Downloading hdbscan-0.8.40.tar.gz (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting pandas>=1.1.5 (from bertopic)\n",
            "  Using cached pandas-2.2.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (89 kB)\n",
            "Collecting plotly>=4.7.0 (from bertopic)\n",
            "  Downloading plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting umap-learn>=0.5.0 (from bertopic)\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/miniconda3/lib/python3.9/site-packages (from gradio) (4.8.0)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Using cached ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Using cached gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
            "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Using cached MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting matplotlib~=3.0 (from gradio)\n",
            "  Using cached matplotlib-3.9.4-cp39-cp39-macosx_10_12_x86_64.whl.metadata (11 kB)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.18-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow (from sentence-transformers)\n",
            "  Using cached pillow-10.4.0-cp39-cp39-macosx_10_10_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pydub (from gradio)\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/miniconda3/lib/python3.9/site-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.11.9-py3-none-macosx_10_12_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Using cached tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /opt/miniconda3/lib/python3.9/site-packages (from gradio-client==1.3.0->gradio) (2025.3.2)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Using cached websockets-12.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting future (from ffmpeg-python)\n",
            "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/chenyuzhong/.local/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /opt/miniconda3/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /opt/miniconda3/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting joblib>=1.0 (from hdbscan>=0.8.29->bertopic)\n",
            "  Using cached joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: certifi in /opt/miniconda3/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /opt/miniconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Using cached h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Collecting hf-xet<2.0.0,>=1.1.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Using cached hf_xet-1.1.0-cp37-abi3-macosx_10_12_x86_64.whl.metadata (494 bytes)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/chenyuzhong/.local/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.21.0)\n",
            "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio)\n",
            "  Using cached contourpy-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio)\n",
            "  Downloading fonttools-4.57.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.5/102.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio)\n",
            "  Using cached kiwisolver-1.4.7-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/chenyuzhong/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas>=1.1.5->bertopic)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=1.1.5->bertopic)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting narwhals>=1.15.1 (from plotly>=4.7.0->bertopic)\n",
            "  Downloading narwhals-1.38.2-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Using cached pydantic_core-2.33.2-cp39-cp39-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading blis-1.3.0.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sympy in /opt/miniconda3/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Using cached regex-2024.11.6-cp39-cp39-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Using cached safetensors-0.5.3-cp38-abi3-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting click>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting numba>=0.51.2 (from umap-learn>=0.5.0->bertopic)\n",
            "  Using cached numba-0.60.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Using cached hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Using cached hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Downloading marisa_trie-1.2.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.2->umap-learn>=0.5.0->bertopic)\n",
            "  Using cached llvmlite-0.43.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/chenyuzhong/.local/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/chenyuzhong/.local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Using cached wrapt-1.17.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.9/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading webvtt_py-0.5.1-py3-none-any.whl (19 kB)\n",
            "Downloading spacy-3.8.5-cp39-cp39-macosx_10_9_x86_64.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "Using cached qdrant_client-1.14.2-py3-none-any.whl (327 kB)\n",
            "Downloading bertopic-0.17.0-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "Using cached gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading cymem-2.0.11-cp39-cp39-macosx_10_9_x86_64.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached grpcio-1.71.0-cp39-cp39-macosx_10_14_universal2.whl (11.3 MB)\n",
            "Using cached huggingface_hub-0.31.1-py3-none-any.whl (484 kB)\n",
            "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_x86_64.whl (14 kB)\n",
            "Using cached matplotlib-3.9.4-cp39-cp39-macosx_10_12_x86_64.whl (7.9 MB)\n",
            "Downloading murmurhash-1.0.12-cp39-cp39-macosx_10_9_x86_64.whl (26 kB)\n",
            "Downloading orjson-3.10.18-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.3/249.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pandas-2.2.3-cp39-cp39-macosx_10_9_x86_64.whl (12.6 MB)\n",
            "Using cached pillow-10.4.0-cp39-cp39-macosx_10_10_x86_64.whl (3.5 MB)\n",
            "Downloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading preshed-3.0.9-cp39-cp39-macosx_10_9_x86_64.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached protobuf-6.30.2-cp39-abi3-macosx_10_9_universal2.whl (417 kB)\n",
            "Using cached pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
            "Using cached pydantic_core-2.33.2-cp39-cp39-macosx_10_12_x86_64.whl (2.0 MB)\n",
            "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.9-py3-none-macosx_10_12_x86_64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hUsing cached scikit_learn-1.6.1-cp39-cp39-macosx_10_9_x86_64.whl (12.1 MB)\n",
            "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Downloading srsly-2.5.1-cp39-cp39-macosx_10_9_x86_64.whl (637 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.3/637.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.6-cp39-cp39-macosx_10_9_x86_64.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.5/898.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "Downloading typer-0.15.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
            "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Downloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Using cached contourpy-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl (265 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.57.0-cp39-cp39-macosx_10_9_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached h2-4.2.0-py3-none-any.whl (60 kB)\n",
            "Using cached hf_xet-1.1.0-cp37-abi3-macosx_10_12_x86_64.whl (5.1 MB)\n",
            "Using cached joblib-1.5.0-py3-none-any.whl (307 kB)\n",
            "Using cached kiwisolver-1.4.7-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n",
            "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-1.38.2-py3-none-any.whl (338 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m338.4/338.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached numba-0.60.0-cp39-cp39-macosx_10_9_x86_64.whl (2.6 MB)\n",
            "Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached regex-2024.11.6-cp39-cp39-macosx_10_9_x86_64.whl (287 kB)\n",
            "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached safetensors-0.5.3-cp38-abi3-macosx_10_12_x86_64.whl (436 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Using cached tokenizers-0.21.1-cp39-abi3-macosx_10_12_x86_64.whl (2.8 MB)\n",
            "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached websockets-12.0-cp39-cp39-macosx_10_9_x86_64.whl (121 kB)\n",
            "Using cached hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Using cached hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Using cached llvmlite-0.43.0-cp39-cp39-macosx_10_9_x86_64.whl (31.1 MB)\n",
            "Downloading marisa_trie-1.2.1-cp39-cp39-macosx_10_9_x86_64.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.8/192.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached wrapt-1.17.2-cp39-cp39-macosx_10_9_x86_64.whl (38 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: hdbscan, blis\n",
            "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.40-cp39-cp39-macosx_10_9_x86_64.whl size=709984 sha256=8111c94e5fe3307b8a150fb4f48515b44b14deb1d0ec2b724c737328ebeb4e38\n",
            "  Stored in directory: /Users/chenyuzhong/Library/Caches/pip/wheels/d7/a1/fa/cf52ce36f64d96efeaea8fcebb37b11c9f27308a914381ff0e\n",
            "  Building wheel for blis (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for blis: filename=blis-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl size=7143697 sha256=e457a6dff6b968cdc803a137216a3456357fbe95f26e1aa1de0033e37f5c7e1b\n",
            "  Stored in directory: /Users/chenyuzhong/Library/Caches/pip/wheels/2b/75/f4/e540f5b1ef1d2610200886c45092f5be21cfe8309ccc48c577\n",
            "Successfully built hdbscan blis\n",
            "Installing collected packages: pytz, pydub, cymem, wrapt, webvtt-py, websockets, wasabi, tzdata, typing-inspection, tomlkit, threadpoolctl, spacy-loggers, spacy-legacy, shellingham, semantic-version, safetensors, ruff, regex, python-multipart, pyparsing, pydantic-core, protobuf, portalocker, Pillow, orjson, narwhals, murmurhash, mdurl, markupsafe, marisa-trie, llvmlite, kiwisolver, joblib, importlib-resources, hyperframe, hpack, hf-xet, grpcio, future, fonttools, ffmpy, cycler, contourpy, cloudpathlib, click, catalogue, blis, annotated-types, aiofiles, uvicorn, starlette, srsly, smart-open, scikit-learn, pydantic, preshed, plotly, pandas, numba, matplotlib, markdown-it-py, language-data, huggingface-hub, h2, ffmpeg-python, tokenizers, rich, pynndescent, langcodes, hdbscan, gradio-client, fastapi, confection, umap-learn, typer, transformers, thinc, qdrant-client, weasel, sentence-transformers, gradio, spacy, bertopic\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed Pillow-10.4.0 aiofiles-23.2.1 annotated-types-0.7.0 bertopic-0.17.0 blis-1.3.0 catalogue-2.0.10 click-8.1.8 cloudpathlib-0.21.0 confection-0.1.5 contourpy-1.3.0 cycler-0.12.1 cymem-2.0.11 fastapi-0.115.12 ffmpeg-python-0.2.0 ffmpy-0.5.0 fonttools-4.57.0 future-1.0.0 gradio-4.44.1 gradio-client-1.3.0 grpcio-1.71.0 h2-4.2.0 hdbscan-0.8.40 hf-xet-1.1.0 hpack-4.1.0 huggingface-hub-0.31.1 hyperframe-6.1.0 importlib-resources-6.5.2 joblib-1.5.0 kiwisolver-1.4.7 langcodes-3.5.0 language-data-1.3.0 llvmlite-0.43.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 markupsafe-2.1.5 matplotlib-3.9.4 mdurl-0.1.2 murmurhash-1.0.12 narwhals-1.38.2 numba-0.60.0 orjson-3.10.18 pandas-2.2.3 plotly-6.0.1 portalocker-2.10.1 preshed-3.0.9 protobuf-6.30.2 pydantic-2.11.4 pydantic-core-2.33.2 pydub-0.25.1 pynndescent-0.5.13 pyparsing-3.2.3 python-multipart-0.0.20 pytz-2025.2 qdrant-client-1.14.2 regex-2024.11.6 rich-14.0.0 ruff-0.11.9 safetensors-0.5.3 scikit-learn-1.6.1 semantic-version-2.10.0 sentence-transformers-4.1.0 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 starlette-0.46.2 thinc-8.3.6 threadpoolctl-3.6.0 tokenizers-0.21.1 tomlkit-0.12.0 transformers-4.51.3 typer-0.15.3 typing-inspection-0.4.0 tzdata-2025.2 umap-learn-0.5.7 uvicorn-0.34.2 wasabi-1.1.3 weasel-0.4.1 websockets-12.0 webvtt-py-0.5.1 wrapt-1.17.2\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/opt/miniconda3/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
            "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
            "  File \"/opt/miniconda3/lib/python3.9/runpy.py\", line 147, in _get_module_details\n",
            "    return _get_module_details(pkg_main_name, error)\n",
            "  File \"/opt/miniconda3/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
            "    __import__(pkg_name)\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/spacy/__init__.py\", line 6, in <module>\n",
            "    from .errors import setup_default_warnings\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/spacy/errors.py\", line 3, in <module>\n",
            "    from .compat import Literal\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/spacy/compat.py\", line 4, in <module>\n",
            "    from thinc.util import copy_array\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/thinc/__init__.py\", line 5, in <module>\n",
            "    from .config import registry\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/thinc/config.py\", line 5, in <module>\n",
            "    from .types import Decorator\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/thinc/types.py\", line 27, in <module>\n",
            "    from .compat import cupy, has_cupy\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/thinc/compat.py\", line 35, in <module>\n",
            "    import torch\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "zsh:1: command not found: apt-get\n"
          ]
        }
      ],
      "source": [
        "!pip install webvtt-py spacy sentence-transformers qdrant-client bertopic gradio ffmpeg-python\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1A91-h0eVk7",
        "outputId": "a0e56bc8-a9ef-4d1c-a19f-28e4c90c11d7"
      },
      "outputs": [],
      "source": [
        "import os, glob\n",
        "from webvtt import WebVTT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h8o1bB-fFfQ",
        "outputId": "fbdab9c3-064b-45f5-c6e8-dc73d9ce1705"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6970, 'caption segments loaded.')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def time_to_seconds(timestamp):\n",
        "    h, m, s = timestamp.split(':')\n",
        "    return int(h) * 3600 + int(m) * 60 + float(s)\n",
        "\n",
        "captions_data = []  # List of dicts: {'video_id', 'start', 'end', 'text'}\n",
        "for video_dir in sorted(os.listdir(\"./data/videos\")):\n",
        "    video_path = os.path.join(\"./data/videos\", video_dir)\n",
        "    if not os.path.isdir(video_path):\n",
        "        continue\n",
        "    # Find English VTT file\n",
        "    vtt_files = glob.glob(os.path.join(video_path, \"*.en.vtt\"))\n",
        "    if not vtt_files:\n",
        "        continue\n",
        "    vtt_path = vtt_files[0]\n",
        "    # Parse captions\n",
        "    for caption in WebVTT().read(vtt_path):\n",
        "        text = caption.text.strip().replace(\"\\n\", \" \")\n",
        "        if not text:\n",
        "            continue\n",
        "        start = time_to_seconds(caption.start)\n",
        "        end = time_to_seconds(caption.end)\n",
        "        captions_data.append({\"video_id\": video_dir, \"start\": start, \"end\": end, \"text\": text})\n",
        "\n",
        "# Sort by video and time\n",
        "captions_data.sort(key=lambda x: (x['video_id'], x['start']))\n",
        "\n",
        "# Deduplicate consecutive segments\n",
        "filtered_caps = []\n",
        "prev_text = None\n",
        "prev_vid = None\n",
        "for cap in captions_data:\n",
        "    if cap[\"video_id\"] != prev_vid:\n",
        "        prev_text = None  # reset at new video\n",
        "        prev_vid = cap[\"video_id\"]\n",
        "    if cap[\"text\"] != prev_text:\n",
        "        filtered_caps.append(cap)\n",
        "    prev_text = cap[\"text\"]\n",
        "captions_data = filtered_caps\n",
        "\n",
        "len(captions_data), \"caption segments loaded.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E4ppJT6flEM",
        "outputId": "e7bf5090-ee86-4d9c-b48b-f64a8ae220ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/opt/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/opt/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/opt/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/opt/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
            "    handle._run()\n",
            "  File \"/opt/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/Users/chenyuzhong/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/x7/dfxqs4mx3f3c9zdl5xrmj4k00000gn/T/ipykernel_13310/3895968736.py\", line 1, in <module>\n",
            "    import spacy\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/spacy/__init__.py\", line 6, in <module>\n",
            "    from .errors import setup_default_warnings\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/spacy/errors.py\", line 3, in <module>\n",
            "    from .compat import Literal\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/spacy/compat.py\", line 4, in <module>\n",
            "    from thinc.util import copy_array\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/thinc/__init__.py\", line 5, in <module>\n",
            "    from .config import registry\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/thinc/config.py\", line 5, in <module>\n",
            "    from .types import Decorator\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/thinc/types.py\", line 27, in <module>\n",
            "    from .compat import cupy, has_cupy\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/thinc/compat.py\", line 35, in <module>\n",
            "    import torch\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 8 merged sentences from captions.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "from itertools import groupby\n",
        "\n",
        "sentences = []  # List of dicts: {'video_id', 'start', 'end', 'sentence'}\n",
        "for video_id, group in groupby(captions_data, key=lambda x: x['video_id']):\n",
        "    group = list(group)\n",
        "    combined_text = \" \".join([seg[\"text\"] for seg in group])\n",
        "    doc = nlp(combined_text)\n",
        "    # Compute cumulative character lengths for segment boundaries\n",
        "    cum_lengths = [0]\n",
        "    for seg in group:\n",
        "        cum_lengths.append(cum_lengths[-1] + len(seg[\"text\"]) + 1)\n",
        "    for sent in doc.sents:\n",
        "        sent_text = sent.text.strip()\n",
        "        if not sent_text:\n",
        "            continue\n",
        "        start_char = sent.start_char\n",
        "        end_char = sent.end_char\n",
        "        # Find segment indices containing sentence start/end\n",
        "        start_idx = max(i for i, length in enumerate(cum_lengths) if length <= start_char)\n",
        "        end_idx = max(i for i, length in enumerate(cum_lengths) if length < end_char)\n",
        "        start_time = group[start_idx][\"start\"]\n",
        "        end_time = group[end_idx][\"end\"]\n",
        "        sentences.append({\n",
        "            \"video_id\": video_id,\n",
        "            \"start\": start_time,\n",
        "            \"end\": end_time,\n",
        "            \"sentence\": sent_text\n",
        "        })\n",
        "\n",
        "print(f\"Created {len(sentences)} merged sentences from captions.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPq0UUxIv47m",
        "outputId": "873f04b1-ca05-428a-e76f-73dc36ffb2b6"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m     22\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(train_examples)\n\u001b[0;32m---> 23\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 4. Define loss and fine-tune\u001b[39;00m\n\u001b[1;32m     26\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mMultipleNegativesRankingLoss(model\u001b[38;5;241m=\u001b[39mmodel)\n",
            "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:350\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 350\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py:143\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ],
      "source": [
        "from itertools import groupby\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "\n",
        "def windowize_sentence(sentence, window_size=50, stride=25):\n",
        "    tokens = sentence.split()  # or use spaCy: [t.text for t in nlp(sentence)]\n",
        "    spans = []\n",
        "    for start in range(0, max(1, len(tokens) - window_size + 1), stride):\n",
        "        span = tokens[start:start + window_size]\n",
        "        spans.append(\" \".join(span))\n",
        "    # If the sentence is shorter than window_size, keep it as one span\n",
        "    if not spans:\n",
        "        spans = [\" \".join(tokens)]\n",
        "    return spans\n",
        "# 1. Load base model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# 2. Build training pairs: consecutive sentences in each video\n",
        "train_examples = []\n",
        "for vid, group in groupby(sentences, key=lambda x: x['video_id']):\n",
        "    group = list(group)\n",
        "    for i in range(len(group) - 1):\n",
        "        s1 = group[i]['sentence'].strip()\n",
        "        s2 = group[i+1]['sentence'].strip()\n",
        "        # Skip empty or too-long examples\n",
        "        if not s1 or not s2 or len(s1) > 500 or len(s2) > 500:\n",
        "            continue\n",
        "        train_examples.append(InputExample(texts=[s1, s2]))\n",
        "\n",
        "# 3. Shuffle and batch\n",
        "import random\n",
        "random.shuffle(train_examples)\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
        "\n",
        "# 4. Define loss and fine-tune\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
        "model.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    epochs=1,\n",
        "    warmup_steps=100\n",
        ")\n",
        "\n",
        "# 5. Save the fine-tuned model\n",
        "model.save(\"fine_tuned_minilm\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sent_texts \u001b[38;5;241m=\u001b[39m [s[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sentences]\n\u001b[0;32m----> 2\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoded sentences to vectors of shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, embeddings\u001b[38;5;241m.\u001b[39mshape)\n",
            "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:742\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    740\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([emb\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[1;32m    741\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 742\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([emb\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(all_embeddings, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    744\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(embedding) \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m all_embeddings]\n",
            "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:742\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    740\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([emb\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[1;32m    741\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 742\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([\u001b[43memb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(all_embeddings, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    744\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(embedding) \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m all_embeddings]\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ],
      "source": [
        "sent_texts = [s[\"sentence\"] for s in sentences]\n",
        "embeddings = model.encode(sent_texts, convert_to_numpy=True)\n",
        "print(\"Encoded sentences to vectors of shape:\", embeddings.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "topic_model = BERTopic()\n",
        "topics, probs = topic_model.fit_transform(sent_texts)\n",
        "print(topic_model.get_topic_info().head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import PointStruct\n",
        "\n",
        "client = QdrantClient(host=\"localhost\", port=6333)\n",
        "collection_name = \"video_captions\"\n",
        "vector_dim = embeddings.shape[1]\n",
        "client.recreate_collection(collection_name=collection_name, vector_size=vector_dim, distance=\"Cosine\")\n",
        "\n",
        "# Prepare points for upserting\n",
        "points = []\n",
        "for i, sent in enumerate(sentences):\n",
        "    payload = {\n",
        "        \"video_id\": sent[\"video_id\"],\n",
        "        \"start\": sent[\"start\"],\n",
        "        \"end\": sent[\"end\"],\n",
        "        \"sentence\": sent[\"sentence\"]\n",
        "    }\n",
        "    points.append(PointStruct(id=i, vector=embeddings[i].tolist(), payload=payload))\n",
        "\n",
        "client.upsert(collection_name=collection_name, points=points)\n",
        "print(f\"Uploaded {len(points)} points to Qdrant collection '{collection_name}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def answer_query(query, top_k=1):\n",
        "    q_vec = model.encode([query], convert_to_numpy=True)[0]\n",
        "    results = client.search(collection_name=collection_name, query_vector=q_vec, limit=top_k)\n",
        "    top = results[0]  # best match\n",
        "    data = top.payload\n",
        "    return data[\"video_id\"], data[\"start\"], data[\"end\"], data[\"sentence\"]\n",
        "\n",
        "# Example query\n",
        "video_id, start, end, sentence = answer_query(\"Explain how convolutional layers work\")\n",
        "print(f\"Top answer: \\\"{sentence}\\\" (Video {video_id}, {start:.1f}-{end:.1f}s)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ffmpeg\n",
        "\n",
        "def extract_clip(video_id, start, end, output_path=\"clip.mp4\"):\n",
        "    # Find the video file for this ID\n",
        "    mp4_files = glob.glob(os.path.join(\"./data/videos\", video_id, \"*.mp4\"))\n",
        "    if not mp4_files:\n",
        "        raise FileNotFoundError(f\"No video found for ID {video_id}\")\n",
        "    video_path = mp4_files[0]\n",
        "    (\n",
        "        ffmpeg\n",
        "        .input(video_path, ss=start, to=end)\n",
        "        .output(output_path, codec=\"copy\")\n",
        "        .run(overwrite_output=True)\n",
        "    )\n",
        "    return output_path\n",
        "\n",
        "# Example: extract the clip for the top result\n",
        "clip_file = extract_clip(video_id, start, end, output_path=f\"clip_{video_id}_{int(start)}_{int(end)}.mp4\")\n",
        "print(f\"Saved clip to {clip_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext gradio\n",
        "\n",
        "%%blocks\n",
        "import gradio as gr\n",
        "\n",
        "def qa_pipeline(question):\n",
        "    vid, s, e, ans = answer_query(question)\n",
        "    clip = extract_clip(vid, s, e, output_path=f\"clip_{vid}_{int(s)}_{int(e)}.mp4\")\n",
        "    return clip, ans\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Chat with Your Video Library\")\n",
        "    inp = gr.Textbox(label=\"Enter your question\")\n",
        "    vid_out = gr.Video(label=\"Relevant clip\")\n",
        "    text_out = gr.Textbox(label=\"Answer sentence\")\n",
        "    inp.submit(qa_pipeline, [inp], [vid_out, text_out])\n",
        "\n",
        "demo\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
